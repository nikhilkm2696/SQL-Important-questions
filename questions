Given a table of candidates and their skills, you're tasked with finding the candidates best suited for an open Data Science job. You want to find candidates who are proficient in Python, Tableau, and PostgreSQL.

Write a query to list the candidates who possess all of the required skills for the job. Sort the output by candidate ID in ascending order.

Assumption:

There are no duplicates in the candidates table.
candidates Table:
Column Name	Type
candidate_id	integer
skill	varchar
candidates Example Input:
candidate_id	skill
123	Python
123	Tableau
123	PostgreSQL
234	R
234	PowerBI
234	SQL Server
345	Python
345	Tableau
Example Output:
candidate_id
123
Explanation
Candidate 123 is displayed because they have Python, Tableau, and PostgreSQL skills. 345 isn't included in the output because they're missing one of the required skills: PostgreSQL.

The dataset you are querying against may have different input & output - this is just an example!

p.s. give the hints below a try if you're stuck and don't know where to start!

p.p.s if you find this problem too tricky, even after the hints, check out my 30-day SQL learning roadmap, which features my favorite free resources to learn SQL! After you strengthen your SQL foundations, I'm sure you'll be more than ready to tackle this question!



Solution
Candidates with a variety of skillsets have applied for this role, but we need candidates who know Python, Tableau, and PostgreSQL.

We'll start by using the IN operator to find candidates which have some of the required skills:

SELECT candidate_id
FROM candidates
WHERE skill IN ('Python', 'Tableau', 'PostgreSQL');
The output should look something like this: (Showing random 5 records)

candidate_id	skill
123	Python
123	Tableau
123	PostgreSQL
345	Python
345	Tableau
We can see from the output that these candidates possess at least one of the necessary skills, but keep in mind, the problem is asking for candidates who have ALL THREE of these skills, so we aren't done quite yet!

It's important to keep in mind that the candidates table does not contain any duplicates, so each combination of candidate and skill is a unique row. Therefore, a candidate should have exactly 3 rows for each of the necessary skills in order to be qualified for the job.

Now, we group the candidates table by candidate ID using the GROUP BY clause and count the number of skills for each group using the COUNT function.

Let's look at the total number of required skills for each candidate:

SELECT
  candidate_id,
  COUNT(skill) AS skill_count
FROM candidates
WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')
GROUP BY candidate_id;
Output:

candidate_id	skill_count
123	3
345	2
Candidate 123 possesses all three of the required skills in this instance, but Candidate 345 possesses only two of the required skills.

In the last step, we'll use HAVING to select only candidates with three skills and ORDER BY the candidate ID, as per the task.

Note that the full solution below counts skills inside the HAVING, not in the SELECT as shown above.

Full Solution:

SELECT candidate_id
FROM candidates
WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')
GROUP BY candidate_id
HAVING COUNT(skill) = 3
ORDER BY candidate_id;

other solution:
select candidate_id from (select candidate_id,Count(candidate_id) from 
(select candidate_id from candidates where skill in ('Python','Tableau','PostgreSQL')) as a

group by candidate_id) as c where count=3 order by candidate_id




2)
Assume you are given the tables below about Facebook pages and page likes. Write a query to return the page IDs of all the Facebook pages that don't have any likes. The output should be in ascending order.

pages Table:
Column Name	Type
page_id	integer
page_name	varchar
pages Example Input:
page_id	page_name
20001	SQL Solutions
20045	Brain Exercises
20701	Tips for Data Analysts
page_likes Table:
Column Name	Type
user_id	integer
page_id	integer
liked_date	datetime
page_likes Example Input:
user_id	page_id	liked_date
111	20001	04/08/2022 00:00:00
121	20045	03/12/2022 00:00:00
156	20001	07/25/2022 00:00:00
Example Output:
page_id
20701
Explanation: The page with ID 20701 has no likes.

The dataset you are querying against may have different input & output - this is just an example!

SOLUTION:There are two ways to go about it. Either LEFT JOIN or RIGHT JOIN can be established between tables pages and page_likes or a subquery can be used to identify which pages have not been liked by any user.

The LEFT JOIN clause starts selecting data from the left table. For each row in the left table (pages), it compares the value in the page_id column with the value of each row in the page_id column in the right table (page_likes).

When page_id are found on both sides, the LEFT JOIN clause creates a new row that contains columns that appear in the SELECT clause and adds this row to the result set.

In case page_id frompages table is not available in page_likes table, the LEFT JOIN clause also creates a new row that contains columns that appear in the SELECT clause. In addition, it fills the columns that come from the page_likes (right table) with NULL. Rows having NULL values in the result is the set of the solution.

Read about LEFT JOIN [1] and RIGHT JOIN [2] to get the better understanding.

Solution #1: Using LEFT OUTER JOIN

SELECT pages.page_id
FROM pages
LEFT OUTER JOIN page_likes AS likes
  ON pages.page_id = likes.page_id
WHERE likes.page_id IS NULL;
Another solution to this problem, since pages with NO LIKES are needed, would be the NOT EXISTS clause (refer to Solution #2). It's an appropriate and efficient operator to get this information. Check out here.

Both methods give the same output.

Solution #2: Using NOT EXISTS

SELECT page_id
FROM pages
WHERE NOT EXISTS (
  SELECT 1
  FROM page_likes AS likes
  WHERE likes.page_id = pages.page_id);
Solution #3: Using EXCEPT

SELECT page_id
FROM pages
EXCEPT
SELECT page_id
FROM page_likes
ORDER BY page_id;


my-solution:::::::::


SELECT page_id from pages
where page_id not in (select distinct(page_id) from page_likes)
order by page_id ASC




3)Tesla is investigating bottlenecks in their production, and they need your help to extract the relevant data. Write a query that determines which parts have begun the assembly process but are not yet finished.

Assumptions

Table parts_assembly contains all parts in production.
A part with no finish_date is an unfinished part.
parts_assembly Table
Column Name	Type
part	string
finish_date	datetime
assembly_step	integer
parts_assembly Example Input
part	finish_date	assembly_step
battery	01/22/2022 00:00:00	1
battery	02/22/2022 00:00:00	2
battery	03/22/2022 00:00:00	3
bumper	01/22/2022 00:00:00	1
bumper	02/22/2022 00:00:00	2
bumper		3
bumper		4
Example Output
part
bumper
Explanation
The only item in the output is "bumper" because step 3 didn't have a finish date.

The dataset you are querying against may have different input & output - this is just an example!



Solution
The parts table already contains all of the parts that are currently in production, meaning that we do not have to do any additional filtering for the parts that are not in production.

All we need to do is extract the parts that are not yet finished. We can accomplish this by filtering for rows with no data present in the finish_date column. We call these missing values NULL.

Some parts might be represented multiple times in the query data because they have several assembly steps that are not yet complete. To solve this, we can group part or apply DISTINCT function to obtain the unique parts.

SELECT part
FROM parts_assembly
WHERE finish_date IS NULL
GROUP BY part;
OR

SELECT DISTINCT part
FROM parts_assembly
WHERE finish_date IS NULL;


mysolution:SELECT DISTINCT(part) FROM parts_assembly where finish_date is NULL;


4)MEDIUM:
This is the same question as problem #11 in the SQL Chapter of Ace the Data Science Interview!

Assume you are given the table below on Uber transactions made by users. Write a query to obtain the third transaction of every user. Output the user id, spend and transaction date.

transactions Table:
Column Name	Type
user_id	integer
spend	decimal
transaction_date	timestamp
transactions Example Input:
user_id	spend	transaction_date
111	100.50	01/08/2022 12:00:00
111	55.00	01/10/2022 12:00:00
121	36.00	01/18/2022 12:00:00
145	24.99	01/26/2022 12:00:00
111	89.60	02/05/2022 12:00:00
Example Output:
user_id	spend	transaction_date
111	89.60	02/05/2022 12:00:00
The dataset you are querying against may have different input & output - this is just an example!

Hint #1

Let's first figure out how we can order the users' transactions with a ranking system by assigning each transaction with a rank which we will need to use later. Do you think we can make use of a window function?

A little tip for you, it's called RANK function.

Check out here to learn about this window function.

MYSOLUTION:select user_id,spend,transaction_date from (select user_id,spend,transaction_date ,
RANK() OVER(PARTITION BY user_id ORDER BY transaction_date ) RANKY
FROM transactions ) as p where ranky=3


Solution
First, we obtain the order of transaction numbers for each user. We can do this by using the ROW_NUMBER window function where we PARTITION the all transactions by user_id and ORDER BY the transaction_date.

SELECT 
  user_id, 
  spend, 
  transaction_date, 
  ROW_NUMBER() OVER (
    PARTITION BY user_id ORDER BY transaction_date) AS row_num
FROM transactions;
Here's how the first 5 rows of output looks like:

user_id	spend	transaction_date	row_num
111	100.50	01/08/2022 12:00:00	1
111	55.00	01/10/2022 12:00:00	2
111	89.60	02/05/2022 12:00:00	3
121	36.00	01/18/2022 12:00:00	1
121	22.20	04/01/2022 12:00:00	2
From there on, we can simply convert the query into a subquery and filter for the users' third transaction which is their third transaction sorted by the transaction date (and is denoted as row_num = 3).

SELECT 
  user_id, 
  spend, 
  transaction_date
FROM (
  -- Insert the above query here 
) AS trans_num 
WHERE row_num = 3;
Results:

user_id	spend	transaction_date
111	89.60	02/05/2022 12:00:00
121	67.90	04/03/2022 12:00:00
Apart from using subquery to solve this question, you can also use a CTE. Do you know the differences between a subquery and a CTE?

A CTE is a temporary data set to be used as part of a query and it exists during the entire query session. A subquery is a nested query. It’s a query within a query and unlike CTE, it can be used within that query only. Read here and here for more understanding.

Both methods give the same output and perform fairly similarly. Differences are CTE is reusable during the entire session and more readable, whereas subquery can be used in FROM and WHERE clauses and can act as a column with a single value. We share more resources here (1, 2, 3) on their use cases.

Solution #1: Using Subquery

SELECT 
  user_id,
  spend,
  transaction_date
FROM (
  SELECT 
    user_id, 
    spend, 
    transaction_date, 
    ROW_NUMBER() OVER (
      PARTITION BY user_id ORDER BY transaction_date) AS row_num
  FROM transactions) AS trans_num 
WHERE row_num = 3;
Solution #2: Using CTE

WITH trans_num AS (
  SELECT 
    user_id, 
    spend, 
    transaction_date, 
    ROW_NUMBER() OVER (
      PARTITION BY user_id ORDER BY transaction_date) AS row_num 
  FROM transactions)
 
SELECT 
  user_id, 
  spend, 
  transaction_date 
FROM trans_num 
WHERE row_num = 3;


5)This is the same question as problem #3 in the SQL Chapter of Ace the Data Science Interview!

Assume that you are given the table below containing information on viewership by device type (where the three types are laptop, tablet, and phone). Define “mobile” as the sum of tablet and phone viewership numbers. Write a query to compare the viewership on laptops versus mobile devices.

Output the total viewership for laptop and mobile devices in the format of "laptop_views" and "mobile_views".

viewership Table:
Column Name	Type
user_id	integer
device_type	string ('laptop', 'tablet', 'phone')
view_time	timestamp
viewership Example Input:
user_id	device_type	view_time
123	tablet	01/02/2022 00:00:00
125	laptop	01/07/2022 00:00:00
128	laptop	02/09/2022 00:00:00
129	phone	02/09/2022 00:00:00
145	tablet	02/24/2022 00:00:00
Example Output:
laptop_views	mobile_views
2	3
Explanation: Given the example input, there are 2 laptop views and 3 mobile views.

The dataset you are querying against may have different input & output - this is just an example!

Hint #1

Try using a CASE statement to group laptop views into laptop_views column and tablet & phone views into mobile_views.

SELECT 
  CASE WHEN _____ = '_____' THEN 1 ELSE 0 END AS laptop_views, 
  CASE WHEN _____ IN ('_____', '_____') THEN 1 ELSE 0 END AS mobile_views 
FROM viewership;


SOLUTION:Solution
To compare the viewership on laptops versus mobile devices, we can use a CASE conditional statement to define the device type according to the question's specifications.

The tablet and phone categories are considered to be the 'mobile' device type and the laptop can be set as its own device type (i.e., 'laptop').

SELECT 
  CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END AS laptop_views, 
  CASE WHEN device_type IN ('tablet', 'phone') THEN 1 ELSE 0 END AS mobile_views 
FROM viewership;
laptop_views	mobile_views
0	1
1	0
1	0
0	1
0	1
Let us explain how the CASE statement works using the mobile_views field as an example.

When the device is a tablet or a phone, it is assigned the value of 1. Otherwise, it is given the value of 0.
The IN operator after device_type means OR, as in when the device type is a table OR phone, then it is assigned the value of 1.
Next, we calculate the number of viewership for laptops and mobiles. We can do so by applying the SUM function.

Solution:

SELECT 
  SUM(CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END) AS laptop_views, 
  SUM(CASE WHEN device_type IN ('tablet', 'phone') THEN 1 ELSE 0 END) AS mobile_views 
FROM viewership;
laptop_views	mobile_views
2	3
Ok, timeout guys!

We want you to take a step back and ask yourself this "Why can't you use the COUNT function instead since we're essentially "counting" the number of viewership?"

Say, we apply the COUNT function to the solution instead.

Run this query and we'll explain why it will give you the wrong output.

-- Incorrect solution
SELECT 
  COUNT(CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END) AS laptop_views, 
  COUNT(CASE WHEN device_type IN ('tablet', 'phone') THEN 1 ELSE 0 END) AS mobile_views 
FROM viewership;
Instead of adding the values of 1 and 0, using COUNT will count the number of rows instead which gives you the following output of 5 laptop views and 5 mobile views. That's counterintuitive!

laptop_views	mobile_views
5	5
There's another way that you can use the COUNT function and obtain the correct output. Since COUNT is counting the number of values in the rows, what you can do is switch out the value of 0 with NULL instead.

-- Another correct solution
SELECT 
  COUNT(CASE WHEN device_type = 'laptop' THEN 1 ELSE NULL END) AS laptop_views, 
  COUNT(CASE WHEN device_type IN ('tablet', 'phone') THEN 1 ELSE NULL END) AS mobile_views 
FROM viewership;
With this query, only the correctly assigned device type gets the value of 1.

COUNT and SUM are two very important functions and are frequently asked in technical interviews. We hope that with this question, you'll know how to apply them appropriately.

select sum(laptop_views) as laptop_views,sum(mobile_views) as mobile_views from (select 
case when device_type='laptop' then 1 else 0 end as laptop_views,
case when device_type in ('phone','tablet') then 1 else 0 end as mobile_views
from viewership) as p;



6)This is the same question as problem #8 in the SQL Chapter of Ace the Data Science Interview!

Assume you are given the table below that shows job postings for all companies on the LinkedIn platform. Write a query to get the number of companies that have posted duplicate job listings.

Clarification:

Duplicate job listings refer to two jobs at the same company with the same title and description.
job_listings Table:
Column Name	Type
job_id	integer
company_id	integer
title	string
description	string
job_listings Example Input:
job_id	company_id	title	description
248	827	Business Analyst	Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.
149	845	Business Analyst	Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.
945	345	Data Analyst	Data analyst reviews data to identify key insights into a business's customers and ways the data can be used to solve problems.
164	345	Data Analyst	Data analyst reviews data to identify key insights into a business's customers and ways the data can be used to solve problems.
172	244	Data Engineer	Data engineer works in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret.
Example Output:
co_w_duplicate_jobs
1
Explanation
Because job IDs 945 and 164 are at the same company (345), and the jobs have the same title and description, there is exactly one company with a duplicate job.

The dataset you are querying against may have different input & output - this is just an example!



Solution
The first step to solving this LinkedIn question correctly is connecting with me on LinkedIn 🥺

But seriously, the first step is to find all the companies with job listings that has the same title and description. We can do that by COUNTing the number of job_ids grouped by company_id, title and description.

SELECT 
  company_id, 
  title, 
  description, 
  COUNT(job_id) AS job_count
FROM job_listings
GROUP BY 
  company_id, 
  title, 
  description;
Output (showing first 5 rows with total of 7 rows):

company_id	title	description	job_count
827	Data Scientist	Data scientist uses data to understand and explain the phenomena around them, and help organizations make better decisions.	2
244	Data Engineer	Data engineer works in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret.	1
845	Business Analyst	Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.	1
244	Software Engineer	Software engineers design and create computer systems and applications to solve real-world problems.	2
345	Data Analyst	Data analyst reviews data to identify key insights into a business's customers and ways the data can be used to solve problems.	2
Next, we convert the previous query into a CTE and filter for when job_count is more than 1 meaning we only want where there are 2 or more duplicate job listings. Then, we apply a DISTINCT on company_id to get the unique company_id and count them.

WITH jobs_grouped AS (
-- Insert above query here
)

SELECT COUNT(DISTINCT company_id) AS co_w_duplicate_jobs
FROM jobs_grouped
WHERE job_count > 1;
Results:

co_w_duplicate_jobs
3
Solution #1: Using CTE

WITH jobs_grouped AS (
  SELECT 
    company_id, 
    title, 
    description, 
    COUNT(job_id) AS job_count
  FROM job_listings
  GROUP BY 
    company_id, 
    title, 
    description)

SELECT COUNT(DISTINCT company_id) AS co_w_duplicate_jobs
FROM jobs_grouped
WHERE job_count > 1;
Solution #2: Using Subquery

SELECT COUNT(DISTINCT company_id) AS co_w_duplicate_jobs
FROM (
  SELECT 
    company_id, 
    title, 
    description, 
    COUNT(job_id) AS job_count
  FROM job_listings
  GROUP BY 
    company_id, 
    title, 
    description) AS jobs_grouped
WHERE job_count > 1;


select count(c) as co_w_duplicate_jobs from
(SELECT COUNT(company_id) as c FROM job_listings 
group by company_id,title,description) as p
where c>1;



7)Given a table of Facebook posts, for each user who posted at least twice in 2021, write a query to find the number of days between each user’s first post of the year and last post of the year in the year 2021. Output the user and number of the days between each user's first and last post.

p.s. If you've read the Ace the Data Science Interview and liked it, consider writing us a review?

posts Table:
Column Name	Type
user_id	integer
post_id	integer
post_date	timestamp
post_content	text
posts Example Input:
user_id	post_id	post_date	post_content
151652	599415	07/10/2021 12:00:00	Need a hug
661093	624356	07/29/2021 13:00:00	Bed. Class 8-12. Work 12-3. Gym 3-5 or 6. Then class 6-10. Another day that's gonna fly by. I miss my girlfriend
004239	784254	07/04/2021 11:00:00	Happy 4th of July!
661093	442560	07/08/2021 14:00:00	Just going to cry myself to sleep after watching Marley and Me.
151652	111766	07/12/2021 19:00:00	I'm so done with covid - need travelling ASAP!
Example Output:
user_id	days_between
151652	2
661093	21


Solution
First, we can use MIN and MAX clauses on the post_date column to retrieve the dates for the first and the last post, and then substract one from another accordingly.

As we are asked to find the difference on a user basis for the year 2021, it is important to GROUP the results by user_id, and then filter for the year 2021. To do so, we can use date_part function, which - as the name suggests - retrieves a part from input date. Thus, in our scenario it is the post_date variable. For more use cases, read more here.

Lastly, to filter out the users who have only posted once during the year, we can use HAVING clause with the COUNT of posts over 1

SELECT 
	user_id, 
    MAX(post_date::DATE) - MIN(post_date::DATE) AS days_between
FROM posts
WHERE DATE_PART('year', post_date::DATE) = 2021 
GROUP BY user_id
HAVING COUNT(post_id)>1;

mysolution:select user_id,
date_part('day',MAX(post_date)::timestamp-MIN(post_date)::timestamp) 
AS days_between
from posts where
EXTRACT('year' from post_date)='2021'
group by user_id
having count(user_id)>1  





8)
Write a query to find the top 2 power users who sent the most messages on Microsoft Teams in August 2022. Display the IDs of these 2 users along with the total number of messages they sent. Output the results in descending count of the messages.

Assumption:

No two users has sent the same number of messages in August 2022.
messages Table:
Column Name	Type
message_id	integer
sender_id	integer
receiver_id	integer
content	varchar
sent_date	datetime
messages Example Input:
message_id	sender_id	receiver_id	content	sent_date
901	3601	4500	You up?	08/03/2022 00:00:00
902	4500	3601	Only if you're buying	08/03/2022 00:00:00
743	3601	8752	Let's take this offline	06/14/2022 00:00:00
922	3601	4500	Get on the call	08/10/2022 00:00:00
Example Output:
sender_id	message_count
3601	2
4500	1
The dataset you are querying against may have different input & output - this is just an example!

Hint #1

Let's take one step at a time.

First, we must ensure that all the messages are sent in August 2022. We can pull the month and year information using the EXTRACT function using the sent_date field in the messages table.

SELECT sender_id, message_id
FROM messages
WHERE EXTRACT(MONTH FROM sent_date) = '8'
  AND EXTRACT(YEAR FROM sent_date) = '2022';
Can you use the COUNT function together with the GROUP BY clause to determine how many messages were sent by each user?



Solution
Before we can find the top 2 Microsoft Teams power users, we need to know how many messages were sent by each Microsoft Teams user in August 2022. We will refer to these users as "senders".

First, we extract the month and year from the sent_date field. Then, we count the messages for each sender and group them based on the sender_id:

SELECT 
  sender_id,
  COUNT(message_id) AS count_messages
FROM messages
WHERE EXTRACT(MONTH FROM sent_date) = '8'
  AND EXTRACT(YEAR FROM sent_date) = '2022'
GROUP BY sender_id;
Here over here to learn more about the EXTRACT function, and here to learn about the GROUP BY clause.

The output from the above query should look something like this:

sender_id	count_messages
2520	3
3601	4
4500	1
Because we're operating under the assumption that no two users can send the same number of messages in August 2022, we know that each number in the count_messages column will only appear once. That means that a simple ORDER BY clause in descending order will give us the result we need. We then use a LIMIT clause to pull only the top 2 results, and we're done!

Solution:

SELECT 
  sender_id,
  COUNT(message_id) AS count_messages
FROM messages
WHERE EXTRACT(MONTH FROM sent_date) = '8'
  AND EXTRACT(YEAR FROM sent_date) = '2022'
GROUP BY sender_id
ORDER BY count_messages DESC
LIMIT 2; 



mysolution:SELECT sender_id,count(sender_id) as message_count FROM messages
where extract(MONTH FROM sent_date)='8' and extract(YEAR FROM sent_date)='2022'
group by sender_id
order by message_count desc limit 2;


9)
Easy

Amazon
Given the reviews table, write a query to get the average stars for each product every month.

The output should include the month in numerical value, product id, and average star rating rounded to two decimal places. Sort the output based on month followed by the product id.

P.S. If you've read the Ace the Data Science Interview, and liked it, consider writing us a review?

reviews Table:
Column Name	Type
review_id	integer
user_id	integer
submit_date	datetime
product_id	integer
stars	integer (1-5)
reviews Example Input:
review_id	user_id	submit_date	product_id	stars
6171	123	06/08/2022 00:00:00	50001	4
7802	265	06/10/2022 00:00:00	69852	4
5293	362	06/18/2022 00:00:00	50001	3
6352	192	07/26/2022 00:00:00	69852	3
4517	981	07/05/2022 00:00:00	69852	2
Example Output:
mth	product	avg_stars
6	50001	3.50
6	69852	4.00
7	69852	2.50
Explanation
In June (month #6), product 50001 had two ratings - 4 and 3, resulting in an average star rating of 3.5.

The dataset you are querying against may have different input & output - this is just an example!

Want to try other Amazon SQL Interview Questions?
Here's some more Amazon SQL Interview Questions:Amazon SQL Interview Questions

Hint #1

Let's take the first step. The question is asking for the month in the output, but we do not see any month column in the reviews table. So, how do we get this column?

If you're thinking of extracting it from the submit_date column, then you're on the right path! The EXTRACT function will help us out here.

Your code snippet should look similar to this:

SELECT EXTRACT(MONTH FROM submit_date) AS mth
FROM reviews;




Solution
As we can see, there is no month column in the reviews table. First, we have to extract the month from the submit_date column.

There is a simple function to extract month from a date. Here's the syntax: EXTRACT(MONTH from column_name)

You can look at this page for more explanation on the EXTRACT function.

After extracting the month in numerical values, get the average of the star ratings and round them to two decimal places. It can be achieved using the functions AVG() and ROUND(). Please refer [1] & [2] for some reading on the functions.

Solution:

SELECT 
  EXTRACT(MONTH FROM submit_date) AS mth,
  product_id,
  ROUND(AVG(stars), 2) AS avg_stars
FROM reviews
GROUP BY EXTRACT(MONTH FROM submit_date), product_id
ORDER BY mth, product_id;
Why can't we write mth in the GROUP BY clause, but we can do so in the ORDER BY clause?

This is the order of sequence of how SQL executes the solution's query from top to bottom:

1 - FROM reviews
2 - GROUP BY EXTRACT(MONTH FROM submit_date) ...
3 - SELECT EXTRACT(MONTH FROM submit_date) AS mth ...
4 - ORDER BY mth ...
SQL runs the GROUP BY clause BEFORE the SELECT statement. Hence, when SQL executes the grouping, it cannot say GROUP BY mth because the mth column only exists AFTER the SELECT statement is executed.

The reason why we can execute mth column in the ORDER BY clause is because it's run after the SELECT statement and mth column has been created.

This is a very popular question in technical interviews so make sure that you learn the order of SQL execution well!



mysolution:


SELECT EXTRACT(MONTH FROM submit_date) as mth,product_id as product,
ROUND((SUM(stars)::decimal/COUNT(product_id))::NUMERIC,2) as avg_stars FROM reviews
group by product_id,EXTRACT(MONTH FROM submit_date)
order by mth ,product_id;

10)
Easy

TikTok
New TikTok users sign up with their emails and each user receives a text confirmation to activate their account. Assume you are given the below tables about emails and texts.

Write a query to display the ids of the users who did not confirm on the first day of sign-up, but confirmed on the second day.

Assumption:

action_date is the date when the user activated their account and confirmed their sign-up through the text.
emails Table:
Column Name	Type
email_id	integer
user_id	integer
signup_date	datetime
emails Example Input:
email_id	user_id	signup_date
125	7771	06/14/2022 00:00:00
433	1052	07/09/2022 00:00:00
texts Table:
Column Name	Type
text_id	integer
email_id	integer
signup_action	string ('Confirmed', 'Not confirmed')
action_date	datetime
texts Example Input:
text_id	email_id	signup_action	action_date
6878	125	Confirmed	06/14/2022 00:00:00
6997	433	Not Confirmed	07/09/2022 00:00:00
7000	433	Confirmed	07/10/2022 00:00:00
Example Output:
user_id
1052
Explanation:
User 1052 is the only user who confirmed their sign up on the second day.

The dataset you are querying against may have different input & output - this is just an example!



Solution
Credits to Deepak K @ Linkedin for sharing such an easy and concise solution that we have to share it with you.

There are 2 conditions that we have to fulfill:

Users who confirmed on the second day. (We'll explain how to define this below)
The texts received must say 'Confirmed'.
First, we join the emails and texts tables on the matching user_id field. Note that you can skip this step as we want to show you how condition no. 1 is defined.

SELECT *
FROM emails 
INNER JOIN texts
  ON emails.email_id = texts.email_id;
Showing you output with selected rows:

email_id	user_id	signup_date	text_id	email_id	signup_action	action_date
433	1052	07/09/2022 00:00:00	6997	433	Not confirmed	07/09/2022 00:00:00
433	1052	07/09/2022 00:00:00	7000	433	Confirmed	07/10/2022 00:00:00
236	6950	07/01/2022 00:00:00	9841	236	Confirmed	07/01/2022 00:00:00
450	8963	08/02/2022 00:00:00	6800	450	Not confirmed	08/03/2022 00:00:00
555	8963	08/09/2022 00:00:00	1255	555	Not confirmed	08/09/2022 00:00:00
555	8963	08/09/2022 00:00:00	2660	555	Not confirmed	08/10/2022 00:00:00
555	8963	08/09/2022 00:00:00	2800	555	Confirmed	08/11/2022 00:00:00
Let's interpret the output together.

Rows 1-2: User 1052 signed up on 07/09/2022 and confirmed their account on the next day, 07/10/2022. This is what we meant by "Users who confirmed on the second day" so the user satisfied both conditions.
Row 3: User 6950 signed up and confirmed their account on the same day, 07/01/2022 so this user fails both conditions.
Rows 4-7: User 8963 signed up twice, once on 08/02/2022 and another time on 08/09/2022, and only confirmed their account on 08/11/2022 which is 3 days after their signup. So, the first condition is not fulfilled.
Now that you understand how we're fulfilling those conditions, let's incorporate them into the solution.

Condition #1: Users who confirmed on the second day

SELECT *
FROM emails 
INNER JOIN texts
  ON emails.email_id = texts.email_id
WHERE texts.action_date = emails.signup_date + INTERVAL '1 day'
Note that you don't need to retrieve all the columns using SELECT *.

The texts.action_date = emails.signup_date + INTERVAL '1 day' condition in the WHERE clause essentially means as we only want users who confirmed on the second day as reflected in the texts.action_date field, then we can simply take emails.signup_date and add an interval of 1 day.

email_id	user_id	signup_date	text_id	signup_action	action_date
433	1052	07/09/2022 00:00:00	7000	Confirmed	07/10/2022 00:00:00
450	8963	08/02/2022 00:00:00	6800	Not confirmed	08/03/2022 00:00:00
555	8963	08/09/2022 00:00:00	2660	Not confirmed	08/10/2022 00:00:00
741	1235	07/25/2022 00:00:00	1568	Confirmed	07/26/2022 00:00:00
Did you see that the action_date is 1 day after the signup_date? We have fulfilled the 1st condition. Moving on to the second condition.

Condition #2: The texts received must say 'Confirmed'

SELECT *
FROM emails 
INNER JOIN texts
  ON emails.email_id = texts.email_id
WHERE texts.action_date = emails.signup_date + INTERVAL '1 day'
  AND texts.signup_action = 'Confirmed';
email_id	user_id	signup_date	text_id	signup_action	action_date
433	1052	07/09/2022 00:00:00	7000	Confirmed	07/10/2022 00:00:00
741	1235	07/25/2022 00:00:00	1568	Confirmed	07/26/2022 00:00:00
Finally, we have the information on users who confirmed their accounts on the day after their sign-up.

Note that the question asks you to output user ids only, not the entire table.

Solution:

SELECT DISTINCT user_id
FROM emails 
INNER JOIN texts
  ON emails.email_id = texts.email_id
WHERE texts.action_date = emails.signup_date + INTERVAL '1 day'
  AND texts.signup_action = 'Confirmed';
  
  
  
  mysolution:
  
  SELECT user_id FROM emails e
inner join texts t
on e.email_id=t.email_id
where signup_action='Confirmed'
and EXTRACT(DAY from e.signup_date)+1=EXTRACT(DAY FROM t.action_date);


11)
Easy

Facebook
This is the same question as problem #1 in the SQL Chapter of Ace the Data Science Interview!

Assume you have an events table on app analytics. Write a query to get the app’s click-through rate (CTR %) in 2022. Output the results in percentages rounded to 2 decimal places.

Notes:

Percentage of click-through rate = 100.0 * Number of clicks / Number of impressions
To avoid integer division, you should multiply the click-through rate by 100.0, not 100.
events Table:
Column Name	Type
app_id	integer
event_type	string
timestamp	datetime
events Example Input:
app_id	event_type	timestamp
123	impression	07/18/2022 11:36:12
123	impression	07/18/2022 11:37:12
123	click	07/18/2022 11:37:42
234	impression	07/18/2022 14:15:12
234	click	07/18/2022 14:16:12
Example Output:
app_id	ctr
123	50.00
234	100.00
Explanation
App 123 has a CTR of 50.00% because this app receives 1 click out of the 2 impressions. Hence, it's 1/2 = 50.00%.

The dataset you are querying against may have different input & output - this is just an example!

Hint #1

The key to solving any question is to list down the steps to solve the question.

Filter for analytics events from the year 2022.
Find the number of clicks and number of impressions.
Calculate the percentage of click-through rate.
Let's start with the first step by filtering for events in the year 2022.

SELECT *
FROM events
WHERE timestamp ___ '2022-01-01' AND timestamp ___ '2023-01-01';
Can you complete the blanks with the correct comparison operators?


Solution
Before we proceed, let's list down the steps to solve the question.

Filter for analytics events from the year 2022.
Find the number of clicks and number of impressions.
Calculate the percentage of the click-through rate.
First, we filter for events from the year 2022 in the WHERE clause by using the appropriate comparison operators.

timestamp >= '2022-01-01' refers to the events on 2022-01-01 and later.
timestamp < means events before 2023-01-01 and does not include 2023-01-01.
SELECT *
FROM events
WHERE timestamp >= '2022-01-01' 
  AND timestamp < '2023-01-01';
Next, we want to find the number of clicks and number of impressions using the CASE statement and how you can interpret it:

If the event_type is 'click', then assign the value of 1. Otherwise, assign the value of 0.

SELECT
  app_id,
  CASE WHEN event_type = 'click' THEN 1 ELSE 0 END AS clicks,
  CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END AS impressions
FROM events
WHERE timestamp >= '2022-01-01' 
  AND timestamp < '2023-01-01';
Showing the first 5 rows of output:

app_id	clicks	impressions
123	0	1
123	0	1
123	1	0
234	0	1
234	1	0
Next, we have to add up the clicks and impressions by simply wrapping the CASE statements with a SUM function.

SELECT
  app_id,
  SUM(CASE WHEN event_type = 'click' THEN 1 ELSE 0 END) AS clicks, 
  SUM(CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END) AS impressions
FROM events
WHERE timestamp >= '2022-01-01' 
  AND timestamp < '2023-01-01'
GROUP BY app_id;
app_id	clicks	impressions
123	2	3
234	1	3
Based on the formula below, we have to divide the number of clicks by the number of impressions and then multiply by 100.0.

Percentage of click-through rate = 100.0 * Number of clicks / Number of impressions

Remember to use the ROUND(_____, 2) function to round up the percentage results to 2 decimal places.

Solution #1: Using SUM(CASE ...)

SELECT
  app_id,
  ROUND(100.0 *
    SUM(CASE WHEN event_type = 'click' THEN 1 ELSE 0 END) /
    SUM(CASE WHEN event_type = 'impression' THEN 1 ELSE 0 END), 2)  AS ctr_rate
FROM events
WHERE timestamp >= '2022-01-01' 
  AND timestamp < '2023-01-01'
GROUP BY app_id;
Solution #2: Using COUNT(CASE ...)

SELECT
  app_id,
  ROUND(100.0 *
    COUNT(CASE WHEN event_type = 'click' THEN 1 ELSE NULL END) /
    COUNT(CASE WHEN event_type = 'impression' THEN 1 ELSE NULL END), 2)  AS ctr_rate
FROM events
WHERE timestamp >= '2022-01-01' 
  AND timestamp < '2023-01-01'
GROUP BY app_id;
Solution #3: Using SUM() FILTER ()

SELECT
  app_id,
  ROUND(100.0 *
    SUM(1) FILTER (WHERE event_type = 'click') /
    SUM(1) FILTER (WHERE event_type = 'impression'), 2) AS ctr_app
FROM events
WHERE timestamp >= '2022-01-01' 
  AND timestamp < '2023-01-01'
GROUP BY app_id;



12))
Easy

Robinhood
This is the same question as problem #2 in the SQL Chapter of Ace the Data Science Interview!

You are given the tables below containing information on Robinhood trades and users. Write a query to list the top three cities that have the most completed trade orders in descending order.

Output the city and number of orders.

trades Table:
Column Name	Type
order_id	integer
user_id	integer
price	decimal
quantity	integer
status	string('Completed' ,'Cancelled')
timestamp	datetime
trades Example Input:
order_id	user_id	price	quantity	status	timestamp
100101	111	9.80	10	Cancelled	08/17/2022 12:00:00
100102	111	10.00	10	Completed	08/17/2022 12:00:00
100259	148	5.10	35	Completed	08/25/2022 12:00:00
100264	148	4.80	40	Completed	08/26/2022 12:00:00
100305	300	10.00	15	Completed	09/05/2022 12:00:00
100400	178	9.90	15	Completed	09/09/2022 12:00:00
100565	265	25.60	5	Completed	12/19/2022 12:00:00
users Table:
Column Name	Type
user_id	integer
city	string
email	string
signup_date	datetime
users Example Input:
user_id	city	email	signup_date
111	San Francisco	rrok10@gmail.com	08/03/2021 12:00:00
148	Boston	sailor9820@gmail.com	08/20/2021 12:00:00
178	San Francisco	harrypotterfan182@gmail.com	01/05/2022 12:00:00
265	Denver	shadower_@hotmail.com	02/26/2022 12:00:00
300	San Francisco	houstoncowboy1122@hotmail.com	06/30/2022 12:00:00
Example Output:
city	total_orders
San Francisco	3
Boston	2
Denver	1
Explanation
In this example, San Francisco has first place with 3 orders, Boston has second place with 2 orders, and Denver has third place with 1 order.

The dataset you are querying against may have different input & output - this is just an example!

Solution
Let's start small by joining the trades and users table based on the related column user_id.

Psst, do you know why we have to join the tables? That's because the 'Completed' order status is residing in the trades table whereas the cities are in the users table.

In the SELECT statement, we pull the city field from the users table and the order_id field from the trades table.

SELECT users.city, trades.order_id
FROM trades
INNER JOIN users
  ON trades.user_id = users.user_id;
Output (showing the first 5 rows only):

city	order_id
San Francisco	100777
San Francisco	100102
San Francisco	100101
Boston	100259
Boston	100264
Now that we have the table containing information on the city and orders, let's retrieve the completed orders by filtering 'Completed' orders. Note that we also want the number of orders which we can find using the COUNT function.

SELECT 
  users.city,
  COUNT(trades.order_id) AS total_orders
FROM trades 
INNER JOIN users 
  ON trades.user_id = users.user_id
WHERE trades.status = 'Completed'
GROUP BY users.city;
GROUP BY statement is often used with aggregate functions (i.e. COUNT, MAX, MIN, SUM, AVG) to group the results by non-aggregate columns. Did you notice that our output is grouped by the city column?

city	total_orders
Boston	1
New York	2
San Francisco	4
Finally, to sort the output from the highest number of completed orders, we sort it in descending order in the ORDER BY clause and LIMIT the results to the top 3 orders.

city	total_orders
San Francisco	4
Boston	3
Denver	2
Full solution:

SELECT 
  users.city, 
  COUNT(trades.order_id) AS total_orders 
FROM trades 
INNER JOIN users 
  ON trades.user_id = users.user_id 
WHERE trades.status = 'Completed' 
GROUP BY users.city 
ORDER BY total_orders DESC
limit 3;

mysolution:
SELECT city,count(status) as total_orders FROM trades t
inner join users u
on u.user_id=t.user_id
where status='Completed'
group by city
order by total_orders desc limit 3;

13)
Easy

JPMorgan Chase
Your team at JPMorgan Chase is soon launching a new credit card, and to gain some context, you are analyzing how many credit cards were issued each month.

Write a query that outputs the name of each credit card and the difference in issued amount between the month with the most cards issued, and the least cards issued. Order the results according to the biggest difference.

monthly_cards_issued Table:
Column Name	Type
issue_month	integer
issue_year	integer
card_name	string
issued_amount	integer
monthly_cards_issued Example Input:
card_name	issued_amount	issue_month	issue_year
Chase Freedom Flex	55000	1	2021
Chase Freedom Flex	60000	2	2021
Chase Freedom Flex	65000	3	2021
Chase Freedom Flex	70000	4	2021
Chase Sapphire Reserve	170000	1	2021
Chase Sapphire Reserve	175000	2	2021
Chase Sapphire Reserve	180000	3	2021
Example Output:
card_name	difference
Chase Freedom Flex	15000
Chase Sapphire Reserve	10000
Explanation
Chase Freedom Flex's best month was 70k cards issued and the worst month was 55k cards, so the difference is 15k cards.

Chase Sapphire Reserve’s best month was 180k cards issued and the worst month was 170k cards, so the difference is 10k cards.

The dataset you are querying against may have different input & output - this is just an example!



Solution
To find the difference between the best and worst performing months in card issuance, you can use the MAX() and MIN() functions.

Apply the functions on the issued_amount column, and simply calculate the difference between the two. As we are asked for the difference between both cards, it is important to group the results by the card name.

Don't forget to order the dataset according to the biggest difference!

SELECT 
  card_name, 
  MAX(issued_amount) - MIN(issued_amount) AS difference
FROM monthly_cards_issued
GROUP BY card_name
ORDER BY difference DESC;

mysolution:

SELECT card_name,(max(issued_amount)-min(issued_amount)) as difference FROM monthly_cards_issued
group by card_name
order by difference desc;


14)Easy

Alibaba
You are trying to find the mean number of items bought per order on Alibaba, rounded to 1 decimal place.

However, instead of doing analytics on all Alibaba orders, you have access to a summary table, which describes how many items were in an order (item_count), and the number of orders that had that many items (order_occurrences).

items_per_order Table:
Column Name	Type
item_count	integer
order_occurrences	integer
items_per_order Example Input:
item_count	order_occurrences
1	500
2	1000
3	800
4	1000
There are 500 orders with 1 item in each order; 1000 orders with 2 items in each order; 800 orders with 3 items in each order.

Example Output:
mean
2.7
Explanation
Let's calculate the arithmetic average:

Total items = (1*500) + (2*1000) + (3*800) + (4*1000) = 8900

Total orders = 500 + 1000 + 800 + 1000 = 3300

Mean = 8900 / 3300 = 2.7

The dataset you are querying against may have different input & output - this is just an example!

Hint #1

Can you take the logic from the Example Output, and turn it into a SQL query?

Mean of item count = Total item count / Total orders

Complete the blank spaces in the following query with the appropriate fields.

SELECT 
  SUM(_____ * _____)/SUM(_____) AS mean
FROM items_per_order;


Solution
Here’s the steps to the solution:

Calculate the weighted average of items per order.
Round the result to 1 decimal.
Step 1
Let's follow the logic in the example output. First, we need to multiply each item_count with the number of occurrences order_occurrences, calculate the sum using SUM(item_count * order_occurrences), and finally divide with the total number of orders using SUM(order_occurrences).

SELECT 
  SUM(item_count*order_occurrences)/SUM(order_occurrences) AS mean
FROM items_per_order;
However, there is a trick we need to account for. By default, both metrics are of integer type (i.e. 3, 5, 6), meaning that division will return an integer. Remember that the question specifically asks for output rounded to 1 decimal place.

To tackle this, it is then necessary to cast either column as a decimal type (i.e. 3.1, 5.2, 6.7). This can be done by simply passing a ::DECIMAL or applying CAST(field AS decimal) on either column.

SELECT 
  SUM(item_count::DECIMAL*order_occurrences)/SUM(order_occurrences) AS mean
FROM items_per_order;
Step 2
Use ROUND(__,1) to round the result to 1 decimal place.

SELECT 
  ROUND(
    SUM(item_count::DECIMAL*order_occurrences)/SUM(order_occurrences)
    ,1) AS mean
FROM items_per_order;


mysolution:



select round(me,1) as mean from
(select sum(item_count::decimal*order_occurrences)/sum(order_occurrences) as me
from items_per_order) as t;


